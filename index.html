<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriately as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DriveQA: A comprehensive multimodal benchmark to evaluate and enhance LLMs' ability to pass driving knowledge tests, covering traffic rules, signs, and right-of-way scenarios.">
  <meta property="og:title" content="DriveQA: Passing the Driving Knowledge Test | ICCV 2025"/>
  <meta property="og:description" content="Can LLMs pass a driving test? We introduce DriveQA, a 474K sample benchmark evaluating MLLMs on traffic rules and visual reasoning for autonomous driving."/>
  <meta property="og:url" content="https://driveqaiccv.github.io/DriveQA/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimensions are 1200X630-->
  <meta property="og:image" content="static/images/driveqa_banner.png" />
  <meta property="og:image:width" content="1770"/>
  <meta property="og:image:height" content="1114"/>


  <meta name="twitter:title" content="DriveQA: Passing the Driving Knowledge Test | ICCV 2025">
  <meta name="twitter:description" content="DriveQA: A comprehensive multimodal benchmark to evaluate if LLMs can pass driving knowledge tests, covering traffic rules, signs, and right-of-way scenarios.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimensions are 1200X600-->
  <meta name="twitter:image" content="static/images/driveqa_banner.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="ICCV 2025, Computer Vision, Autonomous Driving, Large Language Models, Vision-Language Models, VLMs, MLLMs, DriveQA, Driving Knowledge Test, Traffic Rules, Right-of-Way, Traffic Signs">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>DriveQA: Passing the Driving Knowledge Test</title>
  <link rel="icon" type="image/x-icon" href="static/images/driver-license.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h2 class="title is-2 publication-title">
              <img src="static/images/driver-license.ico" alt="car" style="width: 32px; height: 32px; vertical-align: middle; margin-right: 8px;">
              DriveQA: Passing the Driving Knowledge Test
            </h2>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://www.linkedin.com/in/maolin-wei/" target="_blank">Maolin Wei</a><sup>1*</sup>,</span>
                <span class="author-block">
                  <a href="https://wanzhouliu.github.io/" target="_blank">Wanzhou Liu</a><sup>2*</sup>,</span>
                  <span class="author-block">
                    <a href="https://eshed1.github.io/" target="_blank">Eshed Ohn-Bar</a><sup>1</sup>,</span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Boston University<sup>1</sup></span>
                    <span class="author-block">Washington University in St. Louis<sup>2</sup></span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block" style="color: #020f9b;">ICCV 2025</span>
                  </div>
                  <div class="is-size-6 publication-authors">
                    <span class="eql-cntrb"><small><sup>*</sup>Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">

                        <!-- ArXiv abstract Link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="ai ai-arxiv"></i>
                        </span>
                        <span>arXiv</span>
                      </a>
                      </span>

                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- Hugging Face link -->
                <span class="link-block">
                  <a href="" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon" style="vertical-align: middle; font-size: 20px;">ü§ó</span>
                  <span>Dataset</span>
                </a>
              </span>              
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!-- End teaser video -->

<section class="hero teaser" style="margin-top: -30px;">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="content" style="display: flex; justify-content: center;">
        <img src="static/images/driver_llama.png" alt="Driver Llama" width="50%">
      </div>
      <h2 class="subtitle has-text-centered" style="margin-top: -5px; margin-bottom: -5px;">
        <b>Can LLMs Pass a Driving Knowledge Test?</b> <br>
        We introduce a multimodal dataset to evaluate the traffic rule-following capabilities of MLLMs.
      </h2>
    </div>
  </div>
</section>

<!-- Teaser Image -->
<section class="hero teaser" style="margin-top: -30px;">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="content" style="display: flex; justify-content: center;">
        <img src="static/images/driveqa_main.png" alt="DriveQA Teaser" width="100%">
      </div>
      <h4 class="subtitle has-text-centered">
        <b>DriveQA</b>: A comprehensive multimodal benchmark that evaluates and improves LLMs' performance on driving knowledge tests through 474K QA pairs covering traffic rules, signs, and right-of-way scenarios.
      </h4>
    </div>
  </div>
</section>
<!-- End teaser image -->


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop" >
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            If a Large Language Model (LLM) were to take a driving knowledge test today, would it pass?
            Beyond standard spatial and visual question-answering (QA) tasks on current autonomous driving benchmarks,
            driving knowledge tests require <b>a complete understanding of all traffic rules, signage, and right-of-way principles</b>. 
            To pass this test, human drivers must discern various edge cases that rarely appear in real-world datasets. 
            In this work, we present <b>DriveQA</b>, an extensive open-source text and vision-based benchmark that exhaustively covers 
            traffic regulations and scenarios. Through our experiments using DriveQA, we show that 
            (1) state-of-the-art LLMs and Multimodal LLMs (MLLMs) perform well on basic traffic rules but exhibit significant weaknesses 
            in numerical reasoning and complex right-of-way scenarios, traffic sign variations, and spatial layouts, 
            (2) fine-tuning on DriveQA improves accuracy across multiple categories, particularly in regulatory sign recognition 
            and intersection decision-making, 
            (3) controlled variations in DriveQA-V provide insights into model sensitivity to environmental factors such as 
            lighting, perspective, distance, and weather conditions, and 
            (4) pretraining on DriveQA enhances downstream driving task performance, leading to improved results on real-world datasets 
            such as nuScenes and BDD, while also demonstrating that models can internalize text and synthetic traffic knowledge to generalize effectively across downstream QA tasks.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<br>
<br>

<!-- Key features -->
<div class="columns is-centered">
  <div class="column is-one-third">
    <div class="content has-text-centered">
      <h3>üìä Large-Scale Benchmark</h3>
      <p>474K QA pairs<br>
      26K text-based questions<br>
      448K vision-based tasks<br>
      220 traffic sign types</p>
    </div>
  </div>
  <div class="column is-one-third">
    <div class="content has-text-centered">
      <h3>üîç Comprehensive Evaluation</h3>
      <p>19 question categories<br>
      Controlled variations<br>
      Explanations included<br>
      Real + synthetic data</p>
    </div>
  </div>
  <div class="column is-one-third">
    <div class="content has-text-centered">
      <h3>üöó Real-World Transfer</h3>
      <p>Improved nuScenes performance<br>
      Better BDD-OIA results<br>
      Sim-to-real generalization<br>
      Downstream task gains</p>
    </div>
  </div>
</div>
<!-- End key features -->


<!-- Related Work Section -->
<section class="section">
  <div class="container is-max-desktop">    
    <!-- image container -->
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <!-- image -->
          <figure>
            <img src="static/images/table1_comparison.png" 
                 alt="DriveQA Related Work"
                 width="100%">
          </figure>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End related work section -->

<!-- Statistics Section -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Dataset Statistics</h2>
      </div>
    </div>

    <br>
    
    <div class="columns is-centered">
      <!-- left image -->
      <div class="column is-half">
        <div class="content">
          <figure>
            <img src="static/images/driveqa_t.png" 
                 alt="DriveQA-T">
            <figcaption class="has-text-centered">
              Distribution of Question Type in <b>DriveQA-T</b>. The benchmark covers five key domains and 19 sub-class types.
            </figcaption>
          </figure>
        </div>
      </div>
      
      <!-- right image -->
      <div class="column is-half">
        <div class="content">
          <figure>
            <img src="static/images/driveqa_cloud.png" 
                 alt="DriveQA-WordCloud">
            <figcaption class="has-text-centered">
              Word Cloud of Questions in <b>DriveQA</b>. The figure statistically summarizes the language terms in the introduced DriveQA benchmark.
            </figcaption>
          </figure>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End statistics section -->


<!-- Main Results -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Main Results</h2>
      </div>
    </div>

    <br>

    <!-- full width image -->
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content has-text-centered">
          <figure>
            <img src="static/images/results_t_chart.png" 
                 alt="Text QA Results Chart"
                 style="width: 100%;">
          </figure>
        </div>
      </div>
    </div>
    
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-centered">
          <figure>
            <img src="static/images/results_t.png" 
                 alt="Text QA Results"
                 style="width: 100%;">
            <figcaption class="has-text-centered" style="margin-top: 15px; font-size: 0.95em;">
              Challenging Categories on <b>DriveQA-T</b>. We show the results of most difficult 3 types: Limits: Speed and Distance Limits, Parking: Parking and Wheel Positioning, Intersection: Right-of-Way and Lane Selection. The Average is the summary based on all 19 types of questions. We denote with green the top method, and light green second best.
            </figcaption>
          </figure>
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content has-text-centered">
          <figure>
            <img src="static/images/results_v.png" 
                 alt="Image QA Results"
                 style="width: 100%;">
            <figcaption class="has-text-centered" style="margin-top: 15px; font-size: 0.95em;">
              Summarized Results on <b>DriveQA-V</b>. We show model performance (accuracy %) for VQA. The dataset is divided into two main categories: intersections and signs (categorized into camera perspective and type).
            </figcaption>
          </figure>
        </div>
      </div>
    </div>

  </div>
</section>
<!-- End main results -->


<!-- Sim-to-Real Transferability -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Sim-to-Real Transferability and Downstream Task Performance</h2>
      </div>
    </div>

    <br>

    <!-- full width image -->
    <div class="columns is-centered">
      <div class="column is-half">
        <div class="content has-text-centered">
          <figure>
            <img src="static/images/down_figure1.png" 
                 alt="Sim-to-Real Generalization"
                 style="width: 100%;">
            <figcaption class="has-text-centered" style="margin-top: 15px; font-size: 0.95em;">
              <b>Sim-to-Real Generalization.</b> We pre-train on synthetic DriveQA (DQA) and evaluate on real-world Mapillary images. The Mapillary dataset comprises challenging scenarios with various traffic sign placements, occlusion, and illumination.
            </figcaption>
          </figure>
        </div>
      </div>
      
      <div class="column is-half">
        <div class="content has-text-centered">
          <figure>
            <img src="static/images/down_figure2.png" 
                 alt="End-to-End Trajectory Planning Results on nuScenes"
                 style="width: 100%;">
            <figcaption class="has-text-centered" style="margin-top: 15px; font-size: 0.95em;">
              <b>End-to-End Trajectory Planning Results on nuScenes.</b> We compute the L2 error at different prediction horizons (1s, 2s, and 3s). Lower L2 error shows our DriveQA (DQA) dataset can transfer from simulation to real-world driving tasks.
            </figcaption>
          </figure>
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-half">
        <div class="content has-text-centered">
          <figure>
            <img src="static/images/down_figure3.png" 
                 alt="Evaluation on BDD-OIA Dataset"
                 style="width: 100%;">
            <figcaption class="has-text-centered" style="margin-top: 15px; font-size: 0.95em;">
              <b>Evaluation on BDD-OIA Dataset.</b> We report mean F1 score (mF1) and overall F1 score (F1 all) for both action and explanation tasks. The results show that fine-tuning on DriveQA improves performance on both tasks.
            </figcaption>
          </figure>
        </div>
      </div>
    </div>

  </div>
</section>
<!-- End transferability section -->


<!-- Youtube video -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- End video carousel -->


<!-- Paper poster -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{wei2025driveqa,
        title={Passing the Driving Knowledge Test},
        author={Wei, Maolin and Liu, Wanzhou and Ohn-Bar, Eshed},
        booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
        year={2025}
      }</code></pre>
      <p>Please cite DriveQA if you find it helpful!</p>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the¬†<a href="https://nerfies.github.io" target="_blank">Nerfies</a>¬†project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
